name: Load Testing

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of load test to run'
        required: true
        default: 'smoke'
        type: choice
        options:
          - smoke
          - full
          - custom
      custom_vus:
        description: 'Custom VU count (for custom test type)'
        required: false
        default: '100'
        type: string
      custom_duration:
        description: 'Custom test duration (e.g., 5m)'
        required: false
        default: '5m'
        type: string
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  K6_PROJECT_ID: unilingo-load-test

jobs:
  smoke-test:
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'smoke' || github.event_name == 'schedule'
    runs-on: ubuntu-latest
    name: Smoke Test (50 VUs)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup k6
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Validate staging environment
        run: |
          if [ -z "${{ secrets.STAGING_BASE_URL }}" ]; then
            echo "‚ùå STAGING_BASE_URL secret is not set"
            exit 1
          fi
          
          echo "üîç Testing staging environment connectivity..."
          curl -f "${{ secrets.STAGING_BASE_URL }}/api/health" || {
            echo "‚ùå Staging environment is not accessible"
            exit 1
          }
          echo "‚úÖ Staging environment is accessible"

      - name: Run smoke test
        env:
          STAGING_BASE_URL: ${{ secrets.STAGING_BASE_URL }}
          API_KEY: ${{ secrets.API_KEY }}
          BEARER_TOKEN: ${{ secrets.BEARER_TOKEN }}
          CDN_BASE_URL: ${{ secrets.CDN_BASE_URL }}
          QUEUE_DEPTH_ENDPOINT: ${{ secrets.QUEUE_DEPTH_ENDPOINT }}
        run: |
          cd load
          ./run_k6.sh --smoke-test --output-dir ./test-results/smoke

      - name: Upload smoke test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: smoke-test-results
          path: load/test-results/smoke/
          retention-days: 30

      - name: Check smoke test results
        run: |
          if [ -f "load/test-results/smoke/k6_results_*.json" ]; then
            echo "‚úÖ Smoke test completed successfully"
          else
            echo "‚ùå Smoke test failed - no results file found"
            exit 1
          fi

  full-test:
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'full'
    runs-on: ubuntu-latest
    name: Full Production Test (5000 VUs)
    needs: smoke-test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup k6
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Validate staging environment
        run: |
          if [ -z "${{ secrets.STAGING_BASE_URL }}" ]; then
            echo "‚ùå STAGING_BASE_URL secret is not set"
            exit 1
          fi
          
          echo "üîç Testing staging environment connectivity..."
          curl -f "${{ secrets.STAGING_BASE_URL }}/api/health" || {
            echo "‚ùå Staging environment is not accessible"
            exit 1
          }
          echo "‚úÖ Staging environment is accessible"

      - name: Run full production test
        env:
          STAGING_BASE_URL: ${{ secrets.STAGING_BASE_URL }}
          API_KEY: ${{ secrets.API_KEY }}
          BEARER_TOKEN: ${{ secrets.BEARER_TOKEN }}
          CDN_BASE_URL: ${{ secrets.CDN_BASE_URL }}
          QUEUE_DEPTH_ENDPOINT: ${{ secrets.QUEUE_DEPTH_ENDPOINT }}
          VU_COUNT: 5000
          RAMP_UP_DURATION: 5m
          STEADY_STATE_DURATION: 10m
          RAMP_DOWN_DURATION: 2m
          QUEUE_DEPTH_THRESHOLD: 500
          JOB_TIMEOUT_SECONDS: 30
          MAX_JOBS_PER_USER: 3
        run: |
          cd load
          ./run_k6.sh --full-test --output-dir ./test-results/full

      - name: Upload full test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: full-test-results
          path: load/test-results/full/
          retention-days: 30

      - name: Analyze test results
        run: |
          cd load/test-results/full
          
          # Find the most recent k6 results file
          RESULTS_FILE=$(ls -t k6_results_*.json | head -n1)
          
          if [ -z "$RESULTS_FILE" ]; then
            echo "‚ùå No k6 results file found"
            exit 1
          fi
          
          echo "üìä Analyzing test results from: $RESULTS_FILE"
          
          # Extract key metrics using jq
          if command -v jq &> /dev/null; then
            echo "üìà Key Metrics:"
            echo "==============="
            
            # HTTP request metrics
            echo "HTTP Requests:"
            jq -r '.metrics.http_reqs.values.count // "N/A"' "$RESULTS_FILE" | xargs echo "  Total Requests:"
            jq -r '.metrics.http_req_failed.values.rate // "N/A"' "$RESULTS_FILE" | xargs printf "  Error Rate: %.2f%%\n"
            jq -r '.metrics.http_req_duration.values.avg // "N/A"' "$RESULTS_FILE" | xargs printf "  Avg Response Time: %.2fms\n"
            jq -r '.metrics.http_req_duration.values."p(95)" // "N/A"' "$RESULTS_FILE" | xargs printf "  95th Percentile: %.2fms\n"
            
            echo ""
            echo "Job Metrics:"
            jq -r '.metrics.jobs_started.values.count // "N/A"' "$RESULTS_FILE" | xargs echo "  Jobs Started:"
            jq -r '.metrics.jobs_completed.values.count // "N/A"' "$RESULTS_FILE" | xargs echo "  Jobs Completed:"
            jq -r '.metrics.job_success_rate.values.rate // "N/A"' "$RESULTS_FILE" | xargs printf "  Job Success Rate: %.2f%%\n"
            jq -r '.metrics.job_latency_ms.values."p(95)" // "N/A"' "$RESULTS_FILE" | xargs printf "  95th Percentile Job Latency: %.2fms\n"
            
            echo ""
            echo "Queue Metrics:"
            jq -r '.metrics.queue_depth.values.max // "N/A"' "$RESULTS_FILE" | xargs echo "  Max Queue Depth:"
            
            # Check acceptance criteria
            echo ""
            echo "Acceptance Criteria Check:"
            echo "=========================="
            
            # Check job latency (should be < 8000ms for 95th percentile)
            JOB_P95=$(jq -r '.metrics.job_latency_ms.values."p(95)" // 0' "$RESULTS_FILE")
            if (( $(echo "$JOB_P95 < 8000" | bc -l) )); then
              echo "‚úÖ Job latency (95th percentile): ${JOB_P95}ms < 8000ms"
            else
              echo "‚ùå Job latency (95th percentile): ${JOB_P95}ms >= 8000ms"
            fi
            
            # Check error rate (should be < 2%)
            ERROR_RATE=$(jq -r '.metrics.http_req_failed.values.rate // 0' "$RESULTS_FILE")
            ERROR_PERCENT=$(echo "$ERROR_RATE * 100" | bc -l)
            if (( $(echo "$ERROR_RATE < 0.02" | bc -l) )); then
              echo "‚úÖ Error rate: ${ERROR_PERCENT}% < 2%"
            else
              echo "‚ùå Error rate: ${ERROR_PERCENT}% >= 2%"
            fi
            
            # Check job success rate (should be > 99%)
            JOB_SUCCESS_RATE=$(jq -r '.metrics.job_success_rate.values.rate // 0' "$RESULTS_FILE")
            JOB_SUCCESS_PERCENT=$(echo "$JOB_SUCCESS_RATE * 100" | bc -l)
            if (( $(echo "$JOB_SUCCESS_RATE > 0.99" | bc -l) )); then
              echo "‚úÖ Job success rate: ${JOB_SUCCESS_PERCENT}% > 99%"
            else
              echo "‚ùå Job success rate: ${JOB_SUCCESS_PERCENT}% <= 99%"
            fi
            
            # Check queue depth (should be < 500)
            MAX_QUEUE_DEPTH=$(jq -r '.metrics.queue_depth.values.max // 0' "$RESULTS_FILE")
            if (( $(echo "$MAX_QUEUE_DEPTH < 500" | bc -l) )); then
              echo "‚úÖ Max queue depth: ${MAX_QUEUE_DEPTH} < 500"
            else
              echo "‚ùå Max queue depth: ${MAX_QUEUE_DEPTH} >= 500"
            fi
            
          else
            echo "‚ö†Ô∏è jq not available for detailed analysis"
            echo "üìÑ Results file: $RESULTS_FILE"
          fi

      - name: Generate test summary
        if: always()
        run: |
          cd load/test-results/full
          
          # Find the most recent results file
          RESULTS_FILE=$(ls -t k6_results_*.json | head -n1)
          
          if [ -z "$RESULTS_FILE" ]; then
            echo "‚ùå No k6 results file found"
            exit 1
          fi
          
          # Create summary file
          SUMMARY_FILE="test_summary_$(date +%Y%m%d_%H%M%S).md"
          
          cat > "$SUMMARY_FILE" << EOF
          # Load Test Summary
          
          **Test Date:** $(date)
          **Test Type:** Full Production Test (5000 VUs)
          **Results File:** $RESULTS_FILE
          
          ## Quick Results
          
          EOF
          
          if command -v jq &> /dev/null; then
            # Extract key metrics
            TOTAL_REQUESTS=$(jq -r '.metrics.http_reqs.values.count // "N/A"' "$RESULTS_FILE")
            ERROR_RATE=$(jq -r '.metrics.http_req_failed.values.rate // 0' "$RESULTS_FILE")
            ERROR_PERCENT=$(echo "$ERROR_RATE * 100" | bc -l)
            AVG_RESPONSE_TIME=$(jq -r '.metrics.http_req_duration.values.avg // "N/A"' "$RESULTS_FILE")
            P95_RESPONSE_TIME=$(jq -r '.metrics.http_req_duration.values."p(95)" // "N/A"' "$RESULTS_FILE")
            JOBS_STARTED=$(jq -r '.metrics.jobs_started.values.count // "N/A"' "$RESULTS_FILE")
            JOBS_COMPLETED=$(jq -r '.metrics.jobs_completed.values.count // "N/A"' "$RESULTS_FILE")
            JOB_SUCCESS_RATE=$(jq -r '.metrics.job_success_rate.values.rate // 0' "$RESULTS_FILE")
            JOB_SUCCESS_PERCENT=$(echo "$JOB_SUCCESS_RATE * 100" | bc -l)
            JOB_P95=$(jq -r '.metrics.job_latency_ms.values."p(95)" // "N/A"' "$RESULTS_FILE")
            MAX_QUEUE_DEPTH=$(jq -r '.metrics.queue_depth.values.max // "N/A"' "$RESULTS_FILE")
            
            cat >> "$SUMMARY_FILE" << EOF
          - **Total HTTP Requests:** $TOTAL_REQUESTS
          - **Error Rate:** ${ERROR_PERCENT}%
          - **Avg Response Time:** ${AVG_RESPONSE_TIME}ms
          - **95th Percentile Response Time:** ${P95_RESPONSE_TIME}ms
          - **Jobs Started:** $JOBS_STARTED
          - **Jobs Completed:** $JOBS_COMPLETED
          - **Job Success Rate:** ${JOB_SUCCESS_PERCENT}%
          - **95th Percentile Job Latency:** ${JOB_P95}ms
          - **Max Queue Depth:** $MAX_QUEUE_DEPTH
          
          ## Acceptance Criteria
          
          EOF
          
            # Check each criterion
            if (( $(echo "$JOB_P95 < 8000" | bc -l) )); then
              echo "- ‚úÖ Job latency (95th percentile): ${JOB_P95}ms < 8000ms" >> "$SUMMARY_FILE"
            else
              echo "- ‚ùå Job latency (95th percentile): ${JOB_P95}ms >= 8000ms" >> "$SUMMARY_FILE"
            fi
            
            if (( $(echo "$ERROR_RATE < 0.02" | bc -l) )); then
              echo "- ‚úÖ Error rate: ${ERROR_PERCENT}% < 2%" >> "$SUMMARY_FILE"
            else
              echo "- ‚ùå Error rate: ${ERROR_PERCENT}% >= 2%" >> "$SUMMARY_FILE"
            fi
            
            if (( $(echo "$JOB_SUCCESS_RATE > 0.99" | bc -l) )); then
              echo "- ‚úÖ Job success rate: ${JOB_SUCCESS_PERCENT}% > 99%" >> "$SUMMARY_FILE"
            else
              echo "- ‚ùå Job success rate: ${JOB_SUCCESS_PERCENT}% <= 99%" >> "$SUMMARY_FILE"
            fi
            
            if (( $(echo "$MAX_QUEUE_DEPTH < 500" | bc -l) )); then
              echo "- ‚úÖ Max queue depth: ${MAX_QUEUE_DEPTH} < 500" >> "$SUMMARY_FILE"
            else
              echo "- ‚ùå Max queue depth: ${MAX_QUEUE_DEPTH} >= 500" >> "$SUMMARY_FILE"
            fi
          fi
          
          echo "üìÑ Test summary created: $SUMMARY_FILE"

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-summary
          path: load/test-results/full/test_summary_*.md
          retention-days: 30

      - name: Check test results and fail if criteria not met
        run: |
          cd load/test-results/full
          
          # Find the most recent results file
          RESULTS_FILE=$(ls -t k6_results_*.json | head -n1)
          
          if [ -z "$RESULTS_FILE" ]; then
            echo "‚ùå No k6 results file found"
            exit 1
          fi
          
          # Check acceptance criteria and fail if any are not met
          FAILED_CRITERIA=0
          
          if command -v jq &> /dev/null; then
            # Check job latency (should be < 8000ms for 95th percentile)
            JOB_P95=$(jq -r '.metrics.job_latency_ms.values."p(95)" // 0' "$RESULTS_FILE")
            if (( $(echo "$JOB_P95 >= 8000" | bc -l) )); then
              echo "‚ùå FAIL: Job latency (95th percentile): ${JOB_P95}ms >= 8000ms"
              FAILED_CRITERIA=$((FAILED_CRITERIA + 1))
            fi
            
            # Check error rate (should be < 2%)
            ERROR_RATE=$(jq -r '.metrics.http_req_failed.values.rate // 0' "$RESULTS_FILE")
            if (( $(echo "$ERROR_RATE >= 0.02" | bc -l) )); then
              echo "‚ùå FAIL: Error rate: $(echo "$ERROR_RATE * 100" | bc -l)% >= 2%"
              FAILED_CRITERIA=$((FAILED_CRITERIA + 1))
            fi
            
            # Check job success rate (should be > 99%)
            JOB_SUCCESS_RATE=$(jq -r '.metrics.job_success_rate.values.rate // 0' "$RESULTS_FILE")
            if (( $(echo "$JOB_SUCCESS_RATE <= 0.99" | bc -l) )); then
              echo "‚ùå FAIL: Job success rate: $(echo "$JOB_SUCCESS_RATE * 100" | bc -l)% <= 99%"
              FAILED_CRITERIA=$((FAILED_CRITERIA + 1))
            fi
            
            # Check queue depth (should be < 500)
            MAX_QUEUE_DEPTH=$(jq -r '.metrics.queue_depth.values.max // 0' "$RESULTS_FILE")
            if (( $(echo "$MAX_QUEUE_DEPTH >= 500" | bc -l) )); then
              echo "‚ùå FAIL: Max queue depth: ${MAX_QUEUE_DEPTH} >= 500"
              FAILED_CRITERIA=$((FAILED_CRITERIA + 1))
            fi
            
            if [ $FAILED_CRITERIA -gt 0 ]; then
              echo ""
              echo "‚ùå Load test failed: $FAILED_CRITERIA acceptance criteria not met"
              echo "üìä Check the uploaded artifacts for detailed results"
              exit 1
            else
              echo "‚úÖ All acceptance criteria met!"
            fi
          else
            echo "‚ö†Ô∏è jq not available for criteria validation"
            echo "üìÑ Results file: $RESULTS_FILE"
          fi

  custom-test:
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'custom'
    runs-on: ubuntu-latest
    name: Custom Test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup k6
        run: |
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Validate staging environment
        run: |
          if [ -z "${{ secrets.STAGING_BASE_URL }}" ]; then
            echo "‚ùå STAGING_BASE_URL secret is not set"
            exit 1
          fi
          
          echo "üîç Testing staging environment connectivity..."
          curl -f "${{ secrets.STAGING_BASE_URL }}/api/health" || {
            echo "‚ùå Staging environment is not accessible"
            exit 1
          }
          echo "‚úÖ Staging environment is accessible"

      - name: Run custom test
        env:
          STAGING_BASE_URL: ${{ secrets.STAGING_BASE_URL }}
          API_KEY: ${{ secrets.API_KEY }}
          BEARER_TOKEN: ${{ secrets.BEARER_TOKEN }}
          CDN_BASE_URL: ${{ secrets.CDN_BASE_URL }}
          QUEUE_DEPTH_ENDPOINT: ${{ secrets.QUEUE_DEPTH_ENDPOINT }}
          VU_COUNT: ${{ github.event.inputs.custom_vus }}
          STEADY_STATE_DURATION: ${{ github.event.inputs.custom_duration }}
        run: |
          cd load
          ./run_k6.sh \
            --vus ${{ github.event.inputs.custom_vus }} \
            --steady ${{ github.event.inputs.custom_duration }} \
            --output-dir ./test-results/custom

      - name: Upload custom test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: custom-test-results
          path: load/test-results/custom/
          retention-days: 30
