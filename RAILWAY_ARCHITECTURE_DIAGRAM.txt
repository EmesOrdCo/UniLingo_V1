================================================================================
                    UNILINGO RAILWAY BACKEND ARCHITECTURE
                          Current State (v1.0)
================================================================================

┌──────────────────────────────────────────────────────────────────────────┐
│                         CLIENT LAYER                                      │
│                                                                           │
│  ┌────────────────┐  ┌────────────────┐  ┌────────────────┐            │
│  │  Mobile Apps   │  │  Web Browser   │  │   Other APIs   │            │
│  │  (React Native)│  │                │  │                │            │
│  └───────┬────────┘  └───────┬────────┘  └───────┬────────┘            │
│          │                   │                    │                      │
│          └───────────────────┴────────────────────┘                      │
│                              │                                           │
│                         HTTPS Requests                                   │
└──────────────────────────────┼───────────────────────────────────────────┘
                               │
                               ▼
┌──────────────────────────────────────────────────────────────────────────┐
│                      RAILWAY PLATFORM                                     │
│                                                                           │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │                    WEB SERVICE (Port 8080)                         │  │
│  │                    Single Node.js Instance                         │  │
│  │                                                                    │  │
│  │  ┌──────────────────────────────────────────────────────────────┐ │  │
│  │  │                 EXPRESS.JS SERVER                            │ │  │
│  │  │                                                              │ │  │
│  │  │  ┌──────────────────────────────────────────────┐           │ │  │
│  │  │  │          RATE LIMITING LAYER                 │           │ │  │
│  │  │  │  • IP-based: 100 req/15min                   │           │ │  │
│  │  │  │  • User-based (Pronunciation): 100 req/hour  │           │ │  │
│  │  │  │  • User-based (AI): 200 req/hour             │           │ │  │
│  │  │  └──────────────────┬───────────────────────────┘           │ │  │
│  │  │                     ▼                                        │ │  │
│  │  │  ┌──────────────────────────────────────────────┐           │ │  │
│  │  │  │         HTTP ENDPOINT HANDLERS               │           │ │  │
│  │  │  │          (Async/Await Pattern)               │           │ │  │
│  │  │  │                                              │           │ │  │
│  │  │  │  ┌────────────────────────────────────────┐ │           │ │  │
│  │  │  │  │ POST /api/ai/generate-flashcards      │ │           │ │  │
│  │  │  │  │   ├─► OpenAI Queue (5-30s)             │ │           │ │  │
│  │  │  │  │   └─► Blocks HTTP response ❌          │ │           │ │  │
│  │  │  │  ├────────────────────────────────────────┤ │           │ │  │
│  │  │  │  │ POST /api/ai/generate-lesson          │ │           │ │  │
│  │  │  │  │   ├─► Multiple OpenAI calls (30-60s)   │ │           │ │  │
│  │  │  │  │   └─► Blocks HTTP response ❌          │ │           │ │  │
│  │  │  │  ├────────────────────────────────────────┤ │           │ │  │
│  │  │  │  │ POST /api/pronunciation-assess        │ │           │ │  │
│  │  │  │  │   ├─► Azure Speech Queue (2-10s)       │ │           │ │  │
│  │  │  │  │   └─► Blocks HTTP response ❌          │ │           │ │  │
│  │  │  │  ├────────────────────────────────────────┤ │           │ │  │
│  │  │  │  │ POST /api/process-image               │ │           │ │  │
│  │  │  │  │   ├─► Azure Vision OCR (1-3s)          │ │           │ │  │
│  │  │  │  │   └─► Blocks HTTP response ❌          │ │           │ │  │
│  │  │  │  ├────────────────────────────────────────┤ │           │ │  │
│  │  │  │  │ POST /api/process-pdf                 │ │           │ │  │
│  │  │  │  │   ├─► Local pdf-parse (5-20s)          │ │           │ │  │
│  │  │  │  │   └─► Blocks HTTP response ❌          │ │           │ │  │
│  │  │  │  └────────────────────────────────────────┘ │           │ │  │
│  │  │  └──────────────────┬───────────────────────────┘           │ │  │
│  │  │                     ▼                                        │ │  │
│  │  │  ┌──────────────────────────────────────────────┐           │ │  │
│  │  │  │        IN-MEMORY QUEUE LAYER                 │           │ │  │
│  │  │  │                                              │           │ │  │
│  │  │  │  ┌────────────────────────────────────────┐ │           │ │  │
│  │  │  │  │ OpenAI Request Queue                  │ │           │ │  │
│  │  │  │  │  • Sequential processing (1 at a time)│ │           │ │  │
│  │  │  │  │  • 50 req/min, 75k tokens/min         │ │           │ │  │
│  │  │  │  │  • Circuit breaker (5 failures)       │ │           │ │  │
│  │  │  │  │  • Lost on restart ❌                 │ │           │ │  │
│  │  │  │  └────────────────────────────────────────┘ │           │ │  │
│  │  │  │                                              │           │ │  │
│  │  │  │  ┌────────────────────────────────────────┐ │           │ │  │
│  │  │  │  │ Azure Speech Request Queue            │ │           │ │  │
│  │  │  │  │  • Parallel (max 20 concurrent)       │ │           │ │  │
│  │  │  │  │  • Circuit breaker (5 failures)       │ │           │ │  │
│  │  │  │  │  • Lost on restart ❌                 │ │           │ │  │
│  │  │  │  └────────────────────────────────────────┘ │           │ │  │
│  │  │  └──────────────────────────────────────────────┘           │ │  │
│  │  │                                                              │ │  │
│  │  └──────────────────────────────────────────────────────────────┘ │  │
│  │                                                                    │  │
│  └────────────────────────────────────────────────────────────────────┘  │
│                                                                           │
│  ❌ No Worker Service                                                     │
│  ❌ No Redis/Queue System                                                 │
│  ❌ No Auto-scaling Configuration                                         │
│  ❌ No Background Job Processing                                          │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                    External API Calls (Inline)
                                │
                ┌───────────────┼───────────────┐
                ▼               ▼               ▼
┌──────────────────────────────────────────────────────────────────────────┐
│                      EXTERNAL SERVICES                                    │
│                                                                           │
│  ┌─────────────────────┐  ┌──────────────────────┐  ┌─────────────────┐ │
│  │    OpenAI API       │  │  Azure Cognitive     │  │  AWS Services   │ │
│  │                     │  │    Services          │  │                 │ │
│  │  ┌───────────────┐  │  │  ┌────────────────┐ │  │  ┌───────────┐  │ │
│  │  │  GPT-4o-mini  │  │  │  │ Speech Service │ │  │  │  Polly    │  │ │
│  │  │               │  │  │  │  (Pronunciation│ │  │  │  (TTS)    │  │ │
│  │  │ 5-30s/request │  │  │  │   Assessment)  │ │  │  │ 2-15s/req │  │ │
│  │  │               │  │  │  │  2-10s/request │ │  │  └───────────┘  │ │
│  │  │ 50 req/min    │  │  │  │                │ │  │                 │ │
│  │  │ 75k tok/min   │  │  │  │ Max 20         │ │  │  ┌───────────┐  │ │
│  │  │               │  │  │  │ concurrent     │ │  │  │    S3     │  │ │
│  │  └───────────────┘  │  │  └────────────────┘ │  │  │  Storage  │  │ │
│  │                     │  │                      │  │  └───────────┘  │ │
│  │  Circuit Breaker:   │  │  ┌────────────────┐ │  │                 │ │
│  │  • Threshold: 5     │  │  │ Computer Vision│ │  │                 │ │
│  │  • Timeout: 60s     │  │  │      OCR       │ │  │                 │ │
│  │                     │  │  │                │ │  │                 │ │
│  └─────────────────────┘  │  │ 1-3s/request   │ │  └─────────────────┘ │
│                           │  │                │ │                       │
│                           │  │ 5k free/month  │ │                       │
│                           │  │                │ │                       │
│                           │  └────────────────┘ │                       │
│                           │                      │                       │
│                           │  Circuit Breaker:    │                       │
│                           │  • Threshold: 5      │                       │
│                           │  • Timeout: 60s      │                       │
│                           └──────────────────────┘                       │
│                                                                           │
│  ┌─────────────────────────────────────────────────────────────────────┐ │
│  │                      Supabase                                       │ │
│  │  ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐ │ │
│  │  │   PostgreSQL     │  │  Storage Bucket  │  │   Auth Service   │ │ │
│  │  │                  │  │                  │  │                  │ │ │
│  │  │  • esp_lessons   │  │  • Audio_Lessons │  │  • User mgmt     │ │ │
│  │  │  • lesson_vocab  │  │  • User uploads  │  │                  │ │ │
│  │  │  • audio_lessons │  │                  │  │                  │ │ │
│  │  │  • users         │  │                  │  │                  │ │ │
│  │  │                  │  │                  │  │                  │ │ │
│  │  │  Fast queries    │  │  Public access   │  │  JWT tokens      │ │ │
│  │  └──────────────────┘  └──────────────────┘  └──────────────────┘ │ │
│  └─────────────────────────────────────────────────────────────────────┘ │
└───────────────────────────────────────────────────────────────────────────┘


================================================================================
                          DATA FLOW EXAMPLE
                   (User generates flashcards)
================================================================================

1. Mobile App sends POST /api/ai/generate-flashcards
   ├─ Content: 5000 characters
   ├─ Subject: Medical Terminology
   └─ User ID: abc123

2. Railway receives request
   ├─ IP rate limiter: ✅ 15/100 used
   └─ User rate limiter: ✅ 42/200 used

3. Request enters OpenAI queue
   ├─ Queue position: 1
   ├─ Current queue size: 3 requests waiting
   └─ Estimated wait: 45 seconds

4. OpenAI API call (blocking)
   ├─ Sends 5000 chars to GPT-4o-mini
   ├─ Waits 18 seconds for response ⏳
   └─ Receives 40 flashcards

5. Response sent to client
   ├─ Total time: 18 seconds
   └─ User waited entire time ❌

🚨 Problem: During those 18 seconds, 3 other users were also waiting!


================================================================================
                        BOTTLENECK VISUALIZATION
================================================================================

Timeline: 10 users submit AI requests simultaneously at t=0

Without Worker Queue (Current):
────────────────────────────────────────────────────────────────────────────
User 1: [████████████████████] 20s ✓
User 2:                       [█████████████████] 19s ✓
User 3:                                          [████████████] 12s ✓
User 4:                                                        [███████] 7s ✓
User 5:                                                                [██] 2s ✓
User 6:                                                                  [█████] 5s ✓
User 7:                                                                        [█████] 5s ✓
User 8:                                                                              [███] 3s ✓
User 9:                                                                                  [████] 4s ✓
User 10:                                                                                     [██] 2s ⏳

Total time: 79 seconds for 10 users
Average wait: 7.9 seconds per user
Users waiting: Everyone blocks until their turn


With Worker Queue (Recommended):
────────────────────────────────────────────────────────────────────────────
All Users: [✓] 0.2s - Job queued, ID returned
           [Background processing...]
           [Webhook notification when done]

Total time: 0.2 seconds for all users
Average wait: 0.02 seconds per user
Background processing: 20 seconds (doesn't block HTTP)


================================================================================
                    CONCURRENT REQUESTS HANDLING
================================================================================

Current System (1 Instance):

┌────────────────────────────────────────────────────────────────┐
│                  Express.js Event Loop                         │
│                                                                │
│  Request 1 (AI)         ──► OpenAI Queue ──► [⏳ 18s blocking] │
│  Request 2 (AI)         ──► Wait in queue ──► [⏳ 15s blocking]│
│  Request 3 (Pronunciation) ► Azure Queue ──► [⏳ 5s blocking] │
│  Request 4 (Pronunciation) ► Processing ──► [⏳ 7s blocking]   │
│  Request 5 (OCR)        ──► Azure OCR ────► [⏳ 2s blocking]   │
│  Request 6 (Health)     ──► [✓ 50ms]                           │
│                                                                │
│  OpenAI: Sequential (1 at a time)                             │
│  Azure Speech: Parallel (max 20)                              │
│  Azure OCR: Direct                                            │
└────────────────────────────────────────────────────────────────┘

Result: Requests 1 and 2 take 33 seconds total (18+15)
        Requests 3 and 4 can run in parallel


================================================================================
                        RATE LIMIT ENFORCEMENT
================================================================================

Current (In-Memory per Instance):

Instance 1:
┌────────────────────────────┐
│ IP-based Rate Limits       │
│ 192.168.1.1: 45/100        │
│ 192.168.1.2: 89/100        │
│                            │
│ User-based Rate Limits     │
│ user_abc: 12/200 (AI)      │
│ user_abc: 5/100 (Speech)   │
│ user_xyz: 156/200 (AI)     │
└────────────────────────────┘

If scaled to multiple instances:
Instance 1 and Instance 2 have SEPARATE counters ❌
User could bypass limits by hitting different instances!

Recommended (Redis):
┌────────────────────────────┐
│     Shared Redis Store     │
│                            │
│ All instances read/write   │
│ Same rate limit counters   │
│ Distributed enforcement ✓  │
└────────────────────────────┘


================================================================================
                      FAILURE SCENARIOS
================================================================================

Scenario 1: OpenAI Rate Limit Hit
───────────────────────────────────────────────────────────────────────────
1. 50 requests in 1 minute → OpenAI returns 429
2. Circuit breaker opens (after 5 failures)
3. All AI requests blocked for 60 seconds 🚨
4. Users see: "Rate limit exceeded. Try again later."

Impact: Complete AI service outage for 1 minute


Scenario 2: Railway Instance Restart
───────────────────────────────────────────────────────────────────────────
1. Railway deploys new code or restarts instance
2. In-memory queues lost (OpenAI queue: 3 requests) 🚨
3. In-memory rate limits reset
4. Circuit breaker state reset

Impact: Lost requests, users get errors


Scenario 3: Azure Speech Overload
───────────────────────────────────────────────────────────────────────────
1. 25 pronunciation requests arrive simultaneously
2. 20 process immediately (max concurrent)
3. 5 wait in queue
4. User 1-20: Average 5 seconds
5. User 21-25: Wait 5s + their processing time

Impact: Some users experience 10+ second delays


================================================================================
                      MONITORING & OBSERVABILITY
================================================================================

Available Endpoints (IP whitelisted):

GET /api/health                    - Basic health check
GET /api/health/detailed           - Full system health
GET /api/metrics                   - Performance metrics
GET /api/pronunciation/status      - Speech service status
GET /api/ai/status                 - OpenAI service status
GET /api/admin/users/overview      - User activity
GET /api/admin/users/statistics    - Usage statistics
GET /monitoring                    - HTML dashboard

Metrics Tracked:
• Total requests
• Average response time
• Error rate
• Per-service metrics (OpenAI, Azure Speech, Azure OCR)
• Circuit breaker state
• Queue sizes
• User activity and risk scores


================================================================================
                    RECOMMENDED ARCHITECTURE
                       (Future State)
================================================================================

┌──────────────────────────────────────────────────────────────────────────┐
│                         CLIENT LAYER                                      │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                                ▼
┌──────────────────────────────────────────────────────────────────────────┐
│                      RAILWAY PLATFORM                                     │
│                                                                           │
│  ┌────────────────────────────────────────────────────────────────────┐  │
│  │            WEB SERVICE (Auto-scale 1-5 instances)                  │  │
│  │  • Handles HTTP requests                                           │  │
│  │  • Returns job IDs immediately                                     │  │
│  │  • No blocking operations ✓                                        │  │
│  └────────────────────────────┬───────────────────────────────────────┘  │
│                                │                                          │
│                                ▼                                          │
│  ┌─────────────────────────────────────────────────────────────────────┐ │
│  │                     REDIS (Queue + Cache)                           │ │
│  │  • Job queue (BullMQ)                                               │ │
│  │  • Rate limiting (shared)                                           │ │
│  │  • Circuit breaker state                                            │ │
│  │  • Response cache                                                   │ │
│  └────────────────────────────┬───────────────────────────────────────┘ │
│                                │                                          │
│                                ▼                                          │
│  ┌─────────────────────────────────────────────────────────────────────┐ │
│  │          WORKER SERVICE (Auto-scale 1-3 instances)                  │ │
│  │  • Process background jobs                                          │ │
│  │  • OpenAI requests (parallel: 5 concurrent)                         │ │
│  │  • Audio generation (Polly)                                         │ │
│  │  • Long-running operations                                          │ │
│  └─────────────────────────────────────────────────────────────────────┘ │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                                ▼
                        External APIs (same as current)


Benefits:
✅ Instant HTTP responses (< 200ms)
✅ No blocking operations
✅ Horizontal scaling works correctly
✅ Persistent queues (survive restarts)
✅ Better resource utilization
✅ Can handle 10x more traffic


================================================================================
                       COST-BENEFIT ANALYSIS
================================================================================

Current System:
├─ Railway Web Service: $10-20/month
├─ External APIs: $30-50/month
└─ Total: $40-70/month

Handles: ~100 active users
Max concurrent requests: ~20/minute with AI

Recommended System:
├─ Railway Web Service (auto-scale): $15-40/month
├─ Railway Worker Service (auto-scale): $15-40/month
├─ Railway Redis Plugin: $10/month
├─ External APIs: $30-50/month
└─ Total: $70-140/month

Handles: ~1,000 active users
Max concurrent requests: ~200/minute with AI

ROI: 10x capacity for 2x cost


================================================================================
                      IMPLEMENTATION TIMELINE
================================================================================

Week 1: Foundation
├─ Add Redis to Railway
├─ Install BullMQ
├─ Create worker.js
└─ Migrate flashcard generation

Week 2: Migration
├─ Move lesson generation to worker
├─ Move audio generation to worker
├─ Add job status endpoints
└─ Update frontend polling

Week 3: Scaling
├─ Enable auto-scaling
├─ Redis-based rate limiting
├─ APM integration (Sentry)
└─ Alert configuration

Week 4: Optimization
├─ Parallel OpenAI processing
├─ Response caching
├─ Load testing
└─ Documentation


================================================================================
                           CONCLUSION
================================================================================

Current State:
❌ Single instance, no scaling
❌ All API calls block HTTP responses
❌ In-memory queues (lost on restart)
❌ Sequential OpenAI processing
❌ Risk of timeouts under load

Recommended State:
✅ Auto-scaling web + worker services
✅ Redis-backed persistent queues
✅ Instant HTTP responses (job IDs)
✅ Background processing
✅ 10x capacity, 2x cost

Critical Next Steps:
1. Add Redis
2. Create worker service
3. Migrate long-running operations
4. Enable auto-scaling


Report Date: October 12, 2025
Version: 1.0

